{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AlGAkZdsp1YF"
      },
      "source": [
        "# VapeCops: 실시간 흡연 감지 시스템\n",
        "\n",
        "---\n",
        "\n",
        "## 소개\n",
        "\n",
        "VapeCops 프로젝트는 딥러닝 기반의 실시간 흡연 감지 시스템으로, 공공장소에서의 비흡연 환경을 조성하기 위해 개발되었습니다. 이 노트북에서는 Jupyter Notebook 환경에서 TensorFlow와 OpenCV를 활용하여 MobileNet 모델을 학습시키는 과정을 보여줍니다. 학습된 모델은 다양한 형식으로 변환되어 Raspberry Pi와 같은 엣지 디바이스에 배포되며, 흡연 행위를 감지하면 경고음을 울리는 이동식 로봇 플랫폼에 통합됩니다.\n",
        "\n",
        "이 프로젝트를 통해 MobileNet 모델을 학습하고, TFLite 형식으로 변환하여 Raspberry Pi와 같은 엣지 디바이스에서 실시간 감지 시스템을 구축하는 방법을 배울 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9TZcxjhp2--"
      },
      "source": [
        "## Working in Jupyter Notebook\n",
        "\n",
        "이 프로젝트는 Jupyter Notebook 환경에서 진행되었으며, Python과 다양한 딥러닝 라이브러리(TensorFlow, OpenCV 등)를 사용하여 실시간 흡연 감지 모델을 학습시킵니다. Jupyter Notebook은 직관적인 코드 실행 및 시각화 기능을 제공하여 데이터 전처리, 모델 학습 및 평가 과정을 효과적으로 관리할 수 있도록 합니다.\n",
        "\n",
        "> **Note**: Python 3.11 환경을 권장하며, 가상환경을 설정하여 필요한 패키지들을 설치하는 것을 추천합니다.\n",
        "\n",
        "이 Jupyter Notebook은 MobileNet을 사용하여 학습을 진행하였으며, 학습 완료 후 모델을 다양한 형식으로 변환하여 Raspberry Pi에 배포할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NgKvGPEUp69_"
      },
      "source": [
        "### 1. 학습 이미지 수집 및 라벨링\n",
        "\n",
        "모델 학습을 위해 먼저 학습에 사용할 이미지 데이터셋을 준비해야 합니다. 이 프로젝트에서는 사용자가 Kaggle에서 다운로드 받거나, 직접 수집한 데이터셋을 활용하여 학습을 진행합니다.\n",
        "\n",
        "학습 이미지는 다양한 배경과 조명 조건에서 흡연 및 비흡연 상태를 잘 표현할 수 있도록 구성해야 합니다. 각 이미지에는 적절한 라벨링이 필요하며, `smoking`과 `notsmoking` 두 가지 클래스를 포함해야 합니다.\n",
        "\n",
        "#### 데이터셋 구조 예시\n",
        "\n",
        "데이터셋은 아래와 같은 폴더 구조를 따라야 합니다:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kQBAHnt4dlXr"
      },
      "outputs": [],
      "source": [
        "dataset/\n",
        "├── train/\n",
        "│   ├── smoking/\n",
        "│   │   ├── image1.jpg\n",
        "│   │   └── image2.jpg\n",
        "│   └── notsmoking/\n",
        "│       ├── image1.jpg\n",
        "│       └── image2.jpg\n",
        "├── validation/\n",
        "│   ├── smoking/\n",
        "│   │   └── image1.jpg\n",
        "│   └── notsmoking/\n",
        "│       └── image1.jpg\n",
        "└── test/\n",
        "    ├── smoking/\n",
        "    │   └── image1.jpg\n",
        "    └── notsmoking/\n",
        "        └── image1.jpg\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wj9xzDthdlXs"
      },
      "source": [
        "## 데이터셋 압축 해제 및 자동 삭제\n",
        "\n",
        "이 코드는 `dataset.zip` 파일이 현재 디렉토리에 있는 경우, 이를 자동으로 `dataset/` 폴더에 압축 해제하고, 압축 해제 후 `dataset.zip` 파일을 삭제하는 코드 입니다. 데이터셋을 효율적으로 관리하고, 불필요한 파일을 제거하여 저장 공간을 절약할 수 있습니다.\n",
        "\n",
        "> **Note**: 이 스크립트는 `dataset.zip` 파일이 Jupyter Notebook과 같은 디렉토리에 있다고 가정합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syl7gtwThwKx"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "import os\n",
        "\n",
        "# dataset.zip 파일이 같은 폴더에 있다고 가정하고 압축 해제\n",
        "zip_filename = 'dataset.zip'\n",
        "\n",
        "# 압축 파일이 존재하는지 확인하고 압축 해제\n",
        "if os.path.exists(zip_filename):\n",
        "    with ZipFile(zip_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall('dataset')\n",
        "    print(f\"Extracted: {zip_filename} to 'dataset/' folder\")\n",
        "else:\n",
        "    print(f\"Error: {zip_filename} 파일을 찾을 수 없습니다.\")\n",
        "\n",
        "# 압축 파일 삭제\n",
        "if os.path.exists(zip_filename):\n",
        "    os.remove(zip_filename)\n",
        "    print(f\"Deleted: {zip_filename}\")\n",
        "else:\n",
        "    print(f\"Error: {zip_filename} 파일을 삭제할 수 없습니다.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CVRcSNXmhxuG"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "# 현재 디렉토리의 dataset 폴더로 이동\n",
        "os.chdir('dataset')\n",
        "print(\"Current Directory:\", os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99uwnhTtdlXt"
      },
      "source": [
        "## 이미지 데이터 전처리하기\n",
        "\n",
        "이 코드는 `ImageDataGenerator`를 사용하여 이미지 데이터셋을 배치 단위로 생성하는 코드입니다. 이미지 데이터는 픽셀 값을 0~1 사이로 정규화하여 학습에 적합한 형태로 변환됩니다. `generate_data` 함수는 설정된 `target_size`(기본값 124x124), `batch_size`(기본값 32), `class_mode`(기본값 'categorical') 및 `color_mode`를 통해 다양한 이미지 데이터셋을 쉽게 로드할 수 있도록 합니다.\n",
        "\n",
        "> **Note**: `training_set_directory` 변수는 실제 훈련 데이터가 저장된 경로로 설정해야 합니다.\n",
        "\n",
        "```python"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wLokmUUdlXt"
      },
      "source": [
        "#### 1. 훈련 이미지 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gJ-9RSoXdlXt"
      },
      "outputs": [],
      "source": [
        "#필요한 라이브러리 다운로드\n",
        "!pip install tensorflow==2.8\n",
        "!pip install Pillow\n",
        "!pip install scipy\n",
        "!pip install matplotlib\n",
        "!pip install seaborn\n",
        "!pip install scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sc3y-CQdlXt"
      },
      "outputs": [],
      "source": [
        "!pip install protobuf==3.20.*\n",
        "!pip install \"numpy<2\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyntMfbHdlXu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# ImageDataGenerator 생성: 이미지 픽셀값을 0~1 사이로 정규화합니다.\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# 사용자 정의 데이터 생성기 함수\n",
        "def generate_data(generator, directory, target_size=(124, 124), batch_size=32, class_mode='categorical', color_mode='rgb'):\n",
        "    data_gen = generator.flow_from_directory(\n",
        "        directory=directory,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        class_mode=class_mode,\n",
        "        color_mode=color_mode,\n",
        "        shuffle=True  # 훈련 이미지 순서를 무작위로 섞음\n",
        "    )\n",
        "    return data_gen\n",
        "\n",
        "# 경로를 실제 훈련 데이터 폴더 경로로 설정\n",
        "training_set_directory = 'train'  # 이미지 훈련 데이터가 있는 폴더 경로\n",
        "\n",
        "# 사용자 정의 생성기를 사용하여 데이터 로드\n",
        "training_set = generate_data(\n",
        "    train_datagen,\n",
        "    directory=training_set_directory,\n",
        "    target_size=(124, 124),\n",
        "    batch_size=32,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb'\n",
        ")\n",
        "\n",
        "# 데이터 배치 테스트 (첫 번째 배치만 확인)\n",
        "batch = next(training_set)\n",
        "print(\"배치 로드 성공:\", batch[0].shape, batch[1].shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4bTaxt2dlXu"
      },
      "source": [
        "#### 2. 테스트 이미지 데이터 전처리하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jsK_qd8P8ZTj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 테스트 데이터셋을 위한 ImageDataGenerator 생성\n",
        "test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# 테스트 데이터셋 생성\n",
        "test_set = test_datagen.flow_from_directory(\n",
        "    'test',                  # 테스트 데이터가 있는 폴더명\n",
        "    target_size=(124, 124),    # 이미지 크기\n",
        "    shuffle=False,           # 테스트 데이터는 순서를 섞지 않음\n",
        "    class_mode='categorical' # 다중 클래스 레이블을 원-핫 인코딩 형태로 반환\n",
        ")\n",
        "\n",
        "# 검증 데이터셋을 위한 ImageDataGenerator 생성\n",
        "train_datagen = ImageDataGenerator(rescale=1.0/255)\n",
        "\n",
        "# 검증 세트 생성\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    'validation',            # 검증 데이터 디렉토리\n",
        "    target_size=(124, 124),    # 모든 이미지를 75x75로 조정\n",
        "    batch_size=32,\n",
        "    class_mode='categorical'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jeTDPtaVtC3n"
      },
      "source": [
        "## MobileNet 모델 생성 및 레이어 동결\n",
        "\n",
        "이 코드는 사전 학습된 MobileNet 모델을 불러와 새로운 학습에 사용할 준비를 하는 과정입니다.\n",
        "\n",
        "1. **MobileNet 모델 생성**  \n",
        "   - `MobileNet` 클래스를 사용하여 ImageNet 데이터셋으로 사전 학습된 MobileNet 모델을 로드합니다.\n",
        "   - `include_top=False`: 최종 분류 레이어를 제외하고 가져옵니다.\n",
        "   - `weights='imagenet'`: ImageNet 데이터셋으로 학습된 가중치를 사용합니다.\n",
        "   - `input_shape=(75, 75, 3)`: 입력 이미지 크기를 (75, 75)로 지정하여 해당 크기의 RGB 이미지를 처리할 수 있도록 설정합니다.\n",
        "\n",
        "2. **모델 요약 출력**  \n",
        "   - `vgg.summary()`를 통해 모델의 레이어 구성과 파라미터 수를 확인합니다. MobileNet의 구조를 이해하고 모델의 크기와 복잡도를 파악하는 데 유용합니다.\n",
        "\n",
        "3. **레이어 동결**  \n",
        "   - `for` 루프를 사용하여 모델의 모든 레이어를 **동결(freeze)** 처리하여, 학습 중 가중치가 업데이트되지 않도록 설정합니다.\n",
        "   - 이렇게 하면 MobileNet의 사전 학습된 특성 추출 기능을 유지하면서, 최종 분류 레이어만 학습할 수 있어 학습 시간을 절약하고 기존 가중치를 효과적으로 활용할 수 있습니다.\n",
        "\n",
        "이 과정은 Transfer Learning(전이 학습)을 위한 준비 단계로, MobileNet의 특성 추출 능력을 활용하여 새로운 데이터셋에 맞게 추가 학습할 수 있게 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKacLPzadlXv"
      },
      "source": [
        "#### 3. 훈련 이미지 데이터 특징 추출하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MHrFsQsnjREZ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications import MobileNet\n",
        "from tensorflow.keras.layers import Flatten, Dropout, Dense, Input\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# MobileNet 모델 불러오기 (변수명을 vgg로 설정)\n",
        "vgg = MobileNet(include_top=False, input_shape=(124, 124, 3))\n",
        "\n",
        "# 레이어를 동결하여 학습되지 않도록 설정\n",
        "for layer in vgg.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 새 모델 정의\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(124, 124, 3)))        # 모델 입력 정의\n",
        "model.add(vgg)                             # MobileNet 모델 추가 (변수명 vgg)\n",
        "model.add(Flatten())                       # GlobalAveragePooling2D 대신 Flatten 사용\n",
        "model.add(Dropout(0.3))                    # 드롭아웃 추가 (30% 뉴런 제거)\n",
        "model.add(Dense(64, activation='relu'))    # 은닉층 추가\n",
        "model.add(Dropout(0.3))                    # 드롭아웃 추가 (30% 뉴런 제거)\n",
        "model.add(Dense(2, activation='softmax'))  # 출력층 추가\n",
        "\n",
        "# 모델 구조 요약 출력\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMMAx_cWtg9c"
      },
      "source": [
        "#### 4. 분류 모델 환경 설정하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRKaxpwLfRsf"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HV4ahMZtkZF"
      },
      "source": [
        "## ModelCheckpoint를 사용한 모델 가중치 저장 및 학습 설정\n",
        "\n",
        "이 코드는 **모델 학습 과정에서 매 에포크마다 가중치를 저장**하기 위해 `ModelCheckpoint` 콜백을 사용하는 방법을 보여줍니다. 이를 통해 각 에포크에서 학습된 가중치를 별도의 파일로 저장하여, 이후 특정 에포크의 가중치를 불러와 학습을 재개하거나 모델을 평가할 수 있습니다.\n",
        "\n",
        "### 1. ModelCheckpoint 콜백 생성\n",
        "`ModelCheckpoint` 콜백을 설정하여 매 에포크마다 모델의 가중치를 자동으로 저장합니다.\n",
        "\n",
        "- `filepath='model_epoch_{epoch:02d}.h5'`: 파일 이름에 에포크 번호가 포함되도록 설정하여, 예를 들어 `model_epoch_01.h5`, `model_epoch_02.h5`와 같은 형식으로 저장됩니다.\n",
        "- `save_freq='epoch'`: 매 에포크가 종료될 때마다 가중치를 저장합니다.\n",
        "- `save_weights_only=True`: 모델의 가중치만 저장하며, 모델의 구조는 저장하지 않습니다. (구조까지 저장하려면 `False`로 설정)\n",
        "\n",
        "### 2. 모델 학습 설정\n",
        "`model.fit()` 함수에서 학습을 시작하며, `ModelCheckpoint` 콜백을 사용하여 가중치를 자동 저장하도록 설정합니다.\n",
        "\n",
        "- `training_set`: 학습에 사용할 데이터셋\n",
        "- `epochs=12`: 총 12 에포크 동안 학습\n",
        "- `steps_per_epoch=steps_per_epoch`: 각 에포크에서 실행할 스텝(배치) 수\n",
        "- `callbacks=[checkpoint]`: 매 에포크마다 `ModelCheckpoint` 콜백을 사용하여 가중치를 저장\n",
        "\n",
        "이 설정을 통해 학습 과정에서 각 에포크마다 모델 가중치를 저장할 수 있으며, 저장된 가중치를 통해 특정 시점의 모델을 재사용하거나 평가할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggJaTeM1dlXw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "# ModelCheckpoint 설정: 마지막 모델 저장\n",
        "checkpoint = ModelCheckpoint(\n",
        "    'model.h5',                # 저장할 파일 이름\n",
        "    monitor='val_accuracy',         # 검증 정확도를 모니터링\n",
        "    save_best_only=False,           # 매 epoch마다 저장 (동일 파일에 덮어쓰기)\n",
        "    save_weights_only=False,        # 전체 모델 저장\n",
        "    verbose=1                       # 저장 시 메시지 출력\n",
        ")\n",
        "\n",
        "# steps_per_epoch 자동 계산\n",
        "steps_per_epoch = len(training_set)\n",
        "\n",
        "# validation_steps (선택 사항)\n",
        "validation_steps = validation_generator.samples // validation_generator.batch_size\n",
        "\n",
        "# 모델 학습\n",
        "history = model.fit(\n",
        "    training_set,\n",
        "    epochs=8,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=validation_generator,  # 검증 데이터를 추가하여 모니터링 가능하게 함\n",
        "    validation_steps=validation_steps,     # 검증 스텝 수 계산\n",
        "    callbacks=[checkpoint]                 # 체크포인트 콜백 추가\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1oNbC7VdlXw"
      },
      "source": [
        "## 모델 학습 정확도(Accuracy)와 손실(Loss) 그래프 시각화\n",
        "\n",
        "이 코드는 `matplotlib` 라이브러리를 사용하여 **모델 학습 과정**에서의 **정확도(accuracy)**와 **손실(loss)** 변화를 에포크(epoch) 단위로 시각화합니다.  \n",
        "**훈련 데이터**와 **검증 데이터**에 대해 각각 시각화하여 모델 학습 성능을 평가하는 데 유용합니다.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zpCjmv2sGmY"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 정확도 그래프\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='training_accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='validation_accuracy')  # 검증 정확도 추가\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "# 손실 그래프\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='training_loss')\n",
        "plt.plot(history.history['val_loss'], label='validation_loss')  # 검증 손실 추가\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('loss')\n",
        "plt.legend()\n",
        "plt.title('Training and Validation Loss')\n",
        "\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQmlHR1otq5r"
      },
      "source": [
        "#### 4. Saved model directory 형식으로 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "px1Jj6f_dlXw"
      },
      "outputs": [],
      "source": [
        "# SavedModel 형식으로 저장\n",
        "model.save('saved_model_directory', save_format='tf')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enuuGSv7dlXw"
      },
      "source": [
        "#### 4. h5 형식으로 파일 저장"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCHHLZwydlXx"
      },
      "outputs": [],
      "source": [
        "# 모델 저장 (h5 형식)\n",
        "model.save('smoking_classifier.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b81HEp7cto9E"
      },
      "source": [
        "## 합성곱 신경망 모델 평가 및 예측\n",
        "\n",
        "이 코드는 학습된 모델을 테스트 세트에 대해 평가하고, 예측을 수행하는 과정을 보여줍니다.\n",
        "\n",
        "### 4.1 모델 평가\n",
        "- **`model.evaluate(test_set)`**: 테스트 세트를 사용해 모델의 **손실(loss)**과 **정확도(accuracy)**를 평가합니다.\n",
        "  - 출력 예시: `loss: 1.0962 - accuracy: 0.9136` (약 91%의 정확도)\n",
        "\n",
        "### 4.2 예측하기\n",
        "\n",
        "1. **클래스 인덱스 확인**\n",
        "   - **`test_set.class_indices`**: 클래스와 인덱스 간의 매핑을 확인합니다.  \n",
        "     예: `{'notsmoking': 0, 'smoking': 1}`\n",
        "\n",
        "2. **모델 예측 생성**\n",
        "   - **`model.predict(test_set)`**: 테스트 세트에 대한 예측 확률을 생성합니다.\n",
        "   - 각 샘플에 대해 클래스별 확률을 배열로 출력합니다.\n",
        "\n",
        "3. **예측 결과 클래스 추출**\n",
        "   - **`np.argmax(predictions, axis=1)`**: 각 샘플의 예측 확률 중 가장 높은 값을 가진 클래스 인덱스를 추출하여 최종 예측 클래스를 얻습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dv2i56GdlXx"
      },
      "source": [
        "#### 4. 모델 평가하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0hWYNgRHjqP"
      },
      "outputs": [],
      "source": [
        "model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Af2Cfovt1jV"
      },
      "source": [
        "#### 5. 예측하기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3KMLuUoVAPwb"
      },
      "outputs": [],
      "source": [
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ve8WvE5YfI7"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(test_set)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3s--rukSZLpu"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "print(np.argmax(predictions, axis=1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cs5VchTdlXy"
      },
      "source": [
        "## 모델 예측 결과 혼동 행렬 시각화\n",
        "\n",
        "이 코드는 테스트 데이터에 대한 모델의 예측 결과와 실제 레이블을 비교하여 **혼동 행렬(confusion matrix)**을 생성하고 시각화하는 과정입니다. 혼동 행렬은 모델의 분류 성능을 평가하는 데 유용한 도구입니다.\n",
        "\n",
        "### 코드 요약\n",
        "\n",
        "1. **예측 생성**\n",
        "   - `model.predict(test_set)`: 테스트 데이터셋에 대해 예측을 수행합니다.\n",
        "   - `np.argmax(predictions, axis=1)`: 예측 확률 중 가장 높은 값을 가진 클래스 인덱스를 추출하여 최종 예측 클래스를 얻습니다.\n",
        "\n",
        "2. **실제 레이블 가져오기**\n",
        "   - `test_set.classes`: 테스트 데이터셋의 실제 레이블을 가져옵니다.\n",
        "\n",
        "3. **혼동 행렬 계산 및 시각화**\n",
        "   - `confusion_matrix(truth, prediction)`: 실제 레이블과 예측 레이블을 비교하여 혼동 행렬을 계산합니다.\n",
        "   - `sns.heatmap(...)`: Seaborn 라이브러리를 사용해 혼동 행렬을 시각화하여, 각 클래스에 대한 올바른 예측과 오류를 한눈에 볼 수 있도록 합니다.\n",
        "\n",
        "이 과정을 통해 모델이 테스트 데이터에서 각 클래스를 얼마나 잘 예측하는지 시각적으로 확인할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcISkCkYdlXy"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# 테스트 데이터에 대한 예측 생성\n",
        "predictions = model.predict(test_set)  # 모델이 test_set에 대해 예측 수행\n",
        "\n",
        "# 예측 결과에서 가장 높은 확률을 가진 클래스의 인덱스를 추출\n",
        "prediction = np.argmax(predictions, axis=1)\n",
        "\n",
        "# 테스트 데이터의 실제 레이블을 가져옴\n",
        "truth = test_set.classes  # test_set.labels로도 사용할 수 있음\n",
        "\n",
        "# 혼동 행렬 계산\n",
        "conf_matrix = confusion_matrix(truth, prediction)\n",
        "\n",
        "# 혼동 행렬 시각화\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=test_set.class_indices.keys(), yticklabels=test_set.class_indices.keys())\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.ylabel(\"True Label\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIvocIwCdlXy"
      },
      "source": [
        "## 모델 분류 성능 평가: Precision, Recall, F1-score, Accuracy\n",
        "\n",
        "이 코드는 **모델의 예측 결과와 실제 레이블을 비교**하여 분류 성능 지표(Precision, Recall, F1-score, Accuracy)를 계산하고 출력합니다. 이를 통해 모델이 각 클래스에 대해 얼마나 잘 예측하는지 평가할 수 있습니다.\n",
        "\n",
        "### 코드 설명\n",
        "\n",
        "1. **예측 생성 및 실제 레이블 준비**\n",
        "   - `model.predict(test_set)`: 테스트 데이터셋에 대한 예측을 생성합니다.\n",
        "   - `np.argmax(predictions, axis=1)`: 예측 확률 중 가장 높은 값을 가진 클래스 인덱스를 추출합니다.\n",
        "   - `truth = test_set.classes`: 테스트 데이터셋의 실제 레이블을 가져옵니다.\n",
        "\n",
        "2. **분류 성능 지표 출력**\n",
        "   - `classification_report(...)`: **Precision(정밀도)**, **Recall(재현율)**, **F1-score**, **Support**(각 클래스의 샘플 수)를 포함한 분류 성능 보고서를 출력합니다.\n",
        "   - `target_names=test_set.class_indices.keys()`: 클래스 이름을 지정하여 출력 시 클래스 이름이 표시되도록 합니다.\n",
        "\n",
        "3. **정확도(Accuracy) 계산 및 출력**\n",
        "   - `accuracy_score(truth, prediction)`: 전체 정확도를 계산하여 출력합니다.\n",
        "\n",
        "이 과정을 통해 모델의 분류 성능을 종합적으로 평가할 수 있으며, 각 클래스별 성능과 전체 정확도를 확인할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sbI4X12edlXy"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 예측 결과와 실제 레이블\n",
        "predictions = model.predict(test_set)\n",
        "prediction = np.argmax(predictions, axis=1)\n",
        "truth = test_set.classes\n",
        "\n",
        "# Precision, Recall, F1-score, Accuracy 계산 및 출력\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(truth, prediction, target_names=test_set.class_indices.keys()))\n",
        "\n",
        "# Accuracy 계산\n",
        "accuracy = accuracy_score(truth, prediction)\n",
        "print(f\"\\nAccuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVBc9h1GdlXy"
      },
      "source": [
        "## 모델 분류 성능 종합 평가"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC3Cp8BwdlXz"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "# 예측 결과와 실제 레이블\n",
        "predictions = model.predict(test_set)\n",
        "prediction = np.argmax(predictions, axis=1)\n",
        "truth = test_set.classes\n",
        "\n",
        "# Classification Report 계산\n",
        "report = classification_report(truth, prediction, target_names=test_set.class_indices.keys(), output_dict=True)\n",
        "\n",
        "# Accuracy 계산\n",
        "accuracy = accuracy_score(truth, prediction)\n",
        "\n",
        "# 전체 지표 출력\n",
        "print(\"Model Performance Summary:\")\n",
        "print(f\"Precision: {report['weighted avg']['precision']:.4f}\")\n",
        "print(f\"Recall: {report['weighted avg']['recall']:.4f}\")\n",
        "print(f\"F1-score: {report['weighted avg']['f1-score']:.4f}\")\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZZyyFKqdlX0"
      },
      "source": [
        "## Keras 모델을 TensorFlow Lite(TFLite) 형식으로 변환 (Optional)\n",
        "\n",
        "이 코드는 **Keras에서 저장된 .h5 모델을 TensorFlow Lite(TFLite) 형식으로 변환**하여, 모바일 및 임베디드 환경에서 사용할 수 있도록 준비합니다.\n",
        "\n",
        "### 코드 요약\n",
        "1. **모델 로드**  \n",
        "   - `final_model.keras` 파일에서 Keras 모델을 불러옵니다.\n",
        "\n",
        "2. **TFLite 변환**  \n",
        "   - TFLiteConverter를 사용해 모델을 TFLite 형식으로 변환하며, 최적화를 적용하여 모델 크기와 성능을 개선합니다.\n",
        "\n",
        "3. **변환된 모델 저장**  \n",
        "   - `smoking_classifier.tflite` 파일로 저장하여 TFLite 모델을 사용 가능하게 합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9E2ATfgK0gQ"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# .h5 모델 로드\n",
        "model = tf.keras.models.load_model(\"smoking_classifier.keras\")\n",
        "\n",
        "# TFLite 변환기 설정 및 변환\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# 변환된 모델 저장\n",
        "with open(\"smoking_classifier.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rFOb43WdlX0"
      },
      "source": [
        "## Keras 모델을 8비트 정수 양자화하여 TFLite 형식으로 변환 (Optional)\n",
        "\n",
        "이 코드는 **Keras에서 저장된 모델을 8비트 정수 양자화하여 Edge TPU와 호환되는 TensorFlow Lite(TFLite) 형식으로 변환**하는 과정입니다.\n",
        "\n",
        "### 코드 요약\n",
        "1. **대표 데이터셋 생성**  \n",
        "   - 양자화에 사용할 대표 데이터셋을 생성하여, 변환 과정에서 모델의 정밀도를 유지합니다.\n",
        "\n",
        "2. **모델 로드 및 변환기 설정**  \n",
        "   - Keras 모델을 불러와 TFLite 변환기에서 8비트 정수 양자화를 적용하도록 설정합니다.\n",
        "   - Edge TPU 호환성을 위해 입력 및 출력 데이터 타입을 `int8`로 지정합니다.\n",
        "\n",
        "3. **양자화된 모델 저장**  \n",
        "   - 변환된 TFLite 모델을 `smoking_classifier_quantized.tflite` 파일로 저장하여 Edge TPU 환경에서 사용할 수 있도록 준비합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVZjlY9ONVh4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 대표 데이터셋 함수 정의 (양자화에 사용할 샘플 데이터를 제공합니다)\n",
        "def representative_data_gen():\n",
        "    for _ in range(100):  # 예제 100개\n",
        "        # 75x75 이미지 크기로 임의 데이터 생성 (또는 실제 데이터로 교체)\n",
        "        dummy_input = np.random.rand(1, 75, 75, 3) * 255\n",
        "        dummy_input = dummy_input.astype(np.float32)\n",
        "        yield [dummy_input]\n",
        "\n",
        "# 기존 모델 로드\n",
        "model = tf.keras.models.load_model(\"smoking_classifier.keras\")\n",
        "\n",
        "# TFLite 변환기 설정\n",
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "\n",
        "# Edge TPU 호환을 위해 8비트 정수 양자화 설정\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "\n",
        "# 입력과 출력 데이터 타입을 int8로 지정\n",
        "converter.inference_input_type = tf.int8\n",
        "converter.inference_output_type = tf.int8\n",
        "\n",
        "# 대표 데이터셋 설정\n",
        "converter.representative_dataset = representative_data_gen\n",
        "\n",
        "# 양자화된 모델로 변환\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "# 양자화된 모델 저장\n",
        "with open(\"smoking_classifier_quantized.tflite\", \"wb\") as f:\n",
        "    f.write(tflite_model)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python (test)",
      "language": "python",
      "name": "test"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.20"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}